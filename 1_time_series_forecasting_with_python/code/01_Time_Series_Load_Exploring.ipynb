{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47ecc54e",
   "metadata": {},
   "source": [
    "## Load and Explore time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cda85d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6ffac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = os.environ.get('data') # avoid personal information in the notebook\n",
    "data_path = data + '\\TimeSeries\\\\1-daily-total-female-births.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d3d7ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Date\n",
      "1959-01-01    35\n",
      "1959-01-02    32\n",
      "1959-01-03    30\n",
      "1959-01-04    31\n",
      "1959-01-05    44\n",
      "Name: Births, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "series = read_csv(data_path, header=0, index_col=0, parse_dates=True,\n",
    "squeeze=True)\n",
    "print(type(series))\n",
    "print(series.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76c8f71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365\n"
     ]
    }
   ],
   "source": [
    "# number of Observations\n",
    "print(series.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5982e210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "1959-02-01    23\n",
      "1959-02-02    31\n",
      "1959-02-03    44\n",
      "1959-02-04    38\n",
      "1959-02-05    50\n",
      "1959-02-06    38\n",
      "1959-02-07    51\n",
      "1959-02-08    31\n",
      "1959-02-09    31\n",
      "1959-02-10    51\n",
      "1959-02-11    36\n",
      "1959-02-12    45\n",
      "1959-02-13    51\n",
      "1959-02-14    34\n",
      "1959-02-15    52\n",
      "1959-02-16    47\n",
      "1959-02-17    45\n",
      "1959-02-18    46\n",
      "1959-02-19    39\n",
      "1959-02-20    48\n",
      "1959-02-21    37\n",
      "1959-02-22    35\n",
      "1959-02-23    52\n",
      "1959-02-24    42\n",
      "1959-02-25    45\n",
      "1959-02-26    39\n",
      "1959-02-27    37\n",
      "1959-02-28    30\n",
      "Name: Births, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# quering by time\n",
    "print(series['1959-02'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd465d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    365.000000\n",
      "mean      41.980822\n",
      "std        7.348257\n",
      "min       23.000000\n",
      "25%       37.000000\n",
      "50%       42.000000\n",
      "75%       46.000000\n",
      "max       73.000000\n",
      "Name: Births, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# calculate descriptive statistics\n",
    "\n",
    "print(series.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfe3c83",
   "metadata": {},
   "source": [
    "## Basic Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c29cc91",
   "metadata": {},
   "source": [
    "Time series datasert must be transformed to be modeled as a supervised learning problem. We try to predict the daily minimum tempreature given to month and day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf8dbe41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "1981-01-01    20.7\n",
      "1981-01-02    17.9\n",
      "1981-01-03    18.8\n",
      "1981-01-04    14.6\n",
      "1981-01-05    15.8\n",
      "              ... \n",
      "1990-12-27    14.0\n",
      "1990-12-28    13.6\n",
      "1990-12-29    13.5\n",
      "1990-12-30    15.7\n",
      "1990-12-31    13.0\n",
      "Name: Temp, Length: 3650, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#### create date time features of a dataset\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "\n",
    "data = os.environ.get('data') # avoid personal information in the notebook\n",
    "data_path = data + '\\TimeSeries\\\\3-daily-minimum-temperatures.csv'\n",
    "series = read_csv(data_path, header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "593d207c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   month  day  temperature\n",
      "0      1    1         20.7\n",
      "1      1    2         17.9\n",
      "2      1    3         18.8\n",
      "3      1    4         14.6\n",
      "4      1    5         15.8\n"
     ]
    }
   ],
   "source": [
    "df_temp = DataFrame()\n",
    "df_temp['month'] = [series.index[i].month for i in range(len(series))]\n",
    "df_temp['day'] = [series.index[i].day for i in range(len(series))]\n",
    "df_temp['temperature'] = [series[i] for i in range(len(series))]\n",
    "print(df_temp.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb71f594",
   "metadata": {},
   "source": [
    "### Lag Features\n",
    "\n",
    "Lag features are the classical way that a time series forecasting problems are transformed into supervised learning problems. The simplest approach is to precit the value at the next time (t+1) given the value at the curren time(t). The supervised learning problem with shiftet values look as follows:  \n",
    "\n",
    "    Value(t), Value(t+1)  \n",
    "    Value(t), Value(t+1)  \n",
    "    Value(t), Value(t+1)  \n",
    "\n",
    "The Pandas library provides the shift() function to help create these shifted or lag features. Shiftin the dataset by 1 creates the t column, adding a NaN value for the first row.  \n",
    "\n",
    "    Shifted, Original\n",
    "    NaN,      20.7\n",
    "    20.7,     17.9\n",
    "    17.9,     18.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ad4a14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      t   t+1\n",
      "0   NaN  20.7\n",
      "1  20.7  17.9\n",
      "2  17.9  18.8\n",
      "3  18.8  14.6\n",
      "4  14.6  15.8\n"
     ]
    }
   ],
   "source": [
    "from pandas import concat\n",
    "\n",
    "temps = DataFrame(series.values)\n",
    "dataframe = concat([temps.shift(1), temps], axis=1)\n",
    "dataframe.columns = ['t', 't+1']\n",
    "print(dataframe.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ace5a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    t-2   t-1     t   t+1\n",
      "0   NaN   NaN   NaN  20.7\n",
      "1   NaN   NaN  20.7  17.9\n",
      "2   NaN  20.7  17.9  18.8\n",
      "3  20.7  17.9  18.8  14.6\n",
      "4  17.9  18.8  14.6  15.8\n"
     ]
    }
   ],
   "source": [
    "dataframe_3 = concat([temps.shift(3), temps.shift(2), temps.shift(1), temps], axis=1)\n",
    "dataframe_3.columns = ['t-2', 't-1', 't', 't+1']\n",
    "print(dataframe_3.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3498327",
   "metadata": {},
   "source": [
    " We can calculate summary statistics across the values in the sliding window,\n",
    " A difficulty with the sliding window approach is how large to make the window for your problem.  \n",
    " **Rolling Dinwos Statistics**  \n",
    " A step beyond adding raw lagged values is to add a summary of the values at previous time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa78caac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean(t-1,t)   t+1\n",
      "0          NaN  20.7\n",
      "1          NaN  17.9\n",
      "2        19.30  18.8\n",
      "3        18.35  14.6\n",
      "4        16.70  15.8\n"
     ]
    }
   ],
   "source": [
    "temps = DataFrame(series.values)\n",
    "shifted = temps.shift(1)\n",
    "window = shifted.rolling(window=2)\n",
    "means = window.mean()\n",
    "dataframe = concat([means, temps], axis=1)\n",
    "dataframe.columns = ['mean(t-1,t)', 't+1']\n",
    "print(dataframe.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d9ca5",
   "metadata": {},
   "source": [
    "**Expanding Window Statistics**\n",
    "\n",
    "\n",
    "#, Window Values  \n",
    "1, 20.7  \n",
    "2, 20.7, 17.9,  \n",
    "3, 20.7, 17.9, 18.8  \n",
    "4, 20.7, 17.9, 18.8, 14.6  \n",
    "5, 20.7, 17.9, 18.8, 14.6, 15.8  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f30fa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    min       mean   max   t+1\n",
      "0  20.7  20.700000  20.7  17.9\n",
      "1  17.9  19.300000  20.7  18.8\n",
      "2  17.9  19.133333  20.7  14.6\n",
      "3  14.6  18.000000  20.7  15.8\n",
      "4  14.6  17.560000  20.7  15.8\n"
     ]
    }
   ],
   "source": [
    "temps = DataFrame(series.values)\n",
    "window = temps.expanding()\n",
    "dataframe = concat([window.min(), window.mean(), window.max(), temps.shift(-1)], axis=1)\n",
    "dataframe.columns = ['min', 'mean', 'max', 't+1']\n",
    "print(dataframe.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7199c02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
